### Intent
* Create a Scalable ML inference server using pulimi

## Steps Highlevel
* Create a docker image with a inference server which can use hugging face to get the model and then serve it.


